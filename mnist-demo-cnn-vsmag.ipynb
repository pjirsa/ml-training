{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b8cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ce2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = T.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ff1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074f345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()  # pre Python 3.3 syntax\n",
    "\n",
    "    self.conv1 = T.nn.Conv2d(1, 32, 5)  # chnl-in, out, krnl\n",
    "    self.conv2 = T.nn.Conv2d(32, 64, 5)\n",
    "    self.fc1 = T.nn.Linear(1024, 512)   # [64*4*4, x]\n",
    "    self.fc2 = T.nn.Linear(512, 256)\n",
    "    self.fc3 = T.nn.Linear(256, 10)     # 10 classes\n",
    "    self.pool1 = T.nn.MaxPool2d(2, stride=2)\n",
    "    self.pool2 = T.nn.MaxPool2d(2, stride=2)\n",
    "    self.drop1 = T.nn.Dropout(0.25)\n",
    "    self.drop2 = T.nn.Dropout(0.50)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # convolution phase         # x is [bs, 1, 28, 28]\n",
    "    z = T.relu(self.conv1(x))   # Size([bs, 32, 24, 24])\n",
    "    z = self.pool1(z)           # Size([bs, 32, 12, 12])\n",
    "    z = self.drop1(z)\n",
    "    z = T.relu(self.conv2(z))   # Size([bs, 64, 8, 8])\n",
    "    z = self.pool2(z)           # Size([bs, 64, 4, 4])\n",
    "   \n",
    "    # neural network phase\n",
    "    z = z.reshape(-1, 1024)     # Size([bs, 1024])\n",
    "    z = T.relu(self.fc1(z))     # Size([bs, 512])\n",
    "    z = self.drop2(z)\n",
    "    z = T.relu(self.fc2(z))     # Size([bs, 256])\n",
    "    z = self.fc3(z)             # Size([bs, 10])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653a33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, ds):\n",
    "  ldr = T.utils.data.DataLoader(ds,\n",
    "    batch_size=len(ds), shuffle=False)\n",
    "  n_correct = 0\n",
    "  for data in ldr:\n",
    "    (pixels, labels) = data\n",
    "    with T.no_grad():\n",
    "      oupts = model(pixels)\n",
    "    (_, predicteds) = T.max(oupts, 1)\n",
    "    n_correct += (predicteds == labels).sum().item()\n",
    "\n",
    "  acc = (n_correct * 1.0) / len(ds)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8dd1b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin MNIST with CNN demo \n",
      "\n",
      "Creating CNN network with 2 conv and 3 linear \n",
      "\n",
      "bat_size = 100 \n",
      "loss = CrossEntropyLoss()\n",
      "optimizer = SGD\n",
      "max_epochs =   5 \n",
      "lrn_rate = 0.005 \n",
      "\n",
      "Starting training\n",
      "epoch =    0   loss = 1374.2710\n",
      "Done \n",
      "Done \n",
      "Done \n",
      "Done \n",
      "Done \n",
      "\n",
      "Computing model accuracy\n",
      "Accuracy on training data = 0.9029\n",
      "Accuracy on test data = 0.9096\n",
      "\n",
      "Making prediction for fake image: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted class is 'four'\n",
      "\n",
      "Saving trained model state\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\Models\\\\mnist_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 91>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaving trained model state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmnist_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 91\u001b[0m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnd MNIST CNN demo \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchmnistenv\\lib\\site-packages\\torch\\serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchmnistenv\\lib\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchmnistenv\\lib\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\Models\\\\mnist_model.pt'"
     ]
    }
   ],
   "source": [
    "# 0. setup\n",
    "print(\"\\nBegin MNIST with CNN demo \")\n",
    "np.random.seed(1)\n",
    "T.manual_seed(1)\n",
    "\n",
    "# 1. create Dataset\n",
    "Transform = transforms.ToTensor()\n",
    "train_ds = datasets.MNIST(root='../Data', train=True, download=True, transform=Transform)\n",
    "\n",
    "\n",
    "# Load data into batches, If shuffle=train, data will be shuffled on each epoch\n",
    "bat_size = 100\n",
    "train_ldr = DataLoader(train_ds, batch_size=bat_size, shuffle=True)\n",
    "\n",
    "# 2. create network\n",
    "print(\"\\nCreating CNN network with 2 conv and 3 linear \")\n",
    "net = Net().to(device)\n",
    "\n",
    "# 3. train model\n",
    "max_epochs = 5  # 100 gives better results\n",
    "ep_log_interval = 5\n",
    "lrn_rate = 0.005\n",
    "\n",
    "loss_func = T.nn.CrossEntropyLoss()  # does log-softmax()\n",
    "optimizer = T.optim.SGD(net.parameters(), lr=lrn_rate)\n",
    "\n",
    "print(\"\\nbat_size = %3d \" % bat_size)\n",
    "print(\"loss = \" + str(loss_func))\n",
    "print(\"optimizer = SGD\")\n",
    "print(\"max_epochs = %3d \" % max_epochs)\n",
    "print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "print(\"\\nStarting training\")\n",
    "net.train()  # set mode\n",
    "\n",
    "for epoch in range(0, max_epochs):\n",
    "    ep_loss = 0  # for one full epoch\n",
    "    for (batch_idx, batch) in enumerate(train_ldr):\n",
    "        (X, y) = batch  # X = pixels, y = target labels\n",
    "        optimizer.zero_grad()\n",
    "        oupt = net(X)\n",
    "        loss_val = loss_func(oupt, y)  # a tensor\n",
    "        ep_loss += loss_val.item()  # accumulate\n",
    "        loss_val.backward()  # compute grads\n",
    "        optimizer.step()     # update weights\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(\"epoch = %4d   loss = %0.4f\" % \\\n",
    "        (epoch, ep_loss))\n",
    "    print(\"Done \")\n",
    "    \n",
    "# 4. evaluate model accuracy\n",
    "print(\"\\nComputing model accuracy\")\n",
    "net.eval()\n",
    "acc_train = accuracy(net, train_ds)  # all at once\n",
    "print(\"Accuracy on training data = %0.4f\" % acc_train)\n",
    "\n",
    "test_ds = datasets.MNIST(root='../Data', train=False, download=True, transform=Transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=500, shuffle=False)\n",
    "\n",
    "net.eval()\n",
    "acc_test = accuracy(net, test_ds)  # all at once\n",
    "print(\"Accuracy on test data = %0.4f\" % acc_test)\n",
    "\n",
    "# 5. make a prediction\n",
    "print(\"\\nMaking prediction for fake image: \")\n",
    "x = np.zeros(shape=(28,28), dtype=np.float32)\n",
    "for row in range(5,23):\n",
    "    x[row][9] = 180  # vertical line\n",
    "for rc in range(9,19):\n",
    "     x[rc][rc] = 250  # diagonal\n",
    "for col in range(5,15):  \n",
    "    x[14][col] = 200  # horizontal\n",
    "x /= 255.0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.imshow(x, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()\n",
    "\n",
    "digits = ['zero', 'one', 'two', 'three', 'four', 'five', \n",
    "'six', 'seven', 'eight', 'nine' ]\n",
    "x = x.reshape(1, 1, 28, 28)  # 1 image, 1 channel\n",
    "x = T.tensor(x, dtype=T.float32).to(device)\n",
    "with T.no_grad():\n",
    "    oupt = net(x)  # 10 logits like [[-0.12, 1.03, . . ]]\n",
    "am = T.argmax(oupt) # 0 to 9\n",
    "print(\"\\nPredicted class is \\'\" + digits[am] + \"\\'\")\n",
    "\n",
    "# 6. save model\n",
    "print(\"\\nSaving trained model state\")\n",
    "fn = \".\\\\Models\\\\mnist_model.pt\"\n",
    "T.save(net.state_dict(), fn)  \n",
    "\n",
    "print(\"\\nEnd MNIST CNN demo \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
