{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff104095850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./DATA\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = datasets.MNIST(root='./DATA', train=True, download=True, transform=Transform)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./DATA\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = datasets.MNIST(root='./DATA', train=False, download=True, transform=Transform)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28]) \n",
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "image, label = train[0]\n",
    "print('Shape:', image.shape, '\\nLabel:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff061c4ce80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size=784, output_size=10, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        self.d1 = nn.Linear(input_size,layers[0])\n",
    "        self.d2 = nn.Linear(layers[0],layers[1])\n",
    "        self.d3 = nn.Linear(layers[1],output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.d1(X))\n",
    "        X = F.relu(self.d2(X))\n",
    "        X = self.d3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (d1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (d2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (d3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultilayerPerceptron()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Batch shape: torch.Size([100, 1, 28, 28])\n",
      "Batch shape after flattening torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('Initial Batch shape:', images.size())\n",
    "    break\n",
    "print('Batch shape after flattening',images.view(100,-1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 batch:  600 [ 60000/60000] Train loss: 0.00848768\n",
      "epoch:  1 batch:  600 [ 60000/60000] Train loss: 0.00167116\n",
      "epoch:  2 batch:  600 [ 60000/60000] Train loss: 0.03290074\n",
      "epoch:  3 batch:  600 [ 60000/60000] Train loss: 0.00275277\n",
      "epoch:  4 batch:  600 [ 60000/60000] Train loss: 0.00330073\n",
      "epoch:  5 batch:  600 [ 60000/60000] Train loss: 0.00837239\n",
      "epoch:  6 batch:  600 [ 60000/60000] Train loss: 0.00194393\n",
      "epoch:  7 batch:  600 [ 60000/60000] Train loss: 0.00077747\n",
      "epoch:  8 batch:  600 [ 60000/60000] Train loss: 0.00705084\n",
      "epoch:  9 batch:  600 [ 60000/60000] Train loss: 0.00028349\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "\n",
    "        # Apply the model\n",
    "        y_pred = model(X_train.view(100, -1)) # Here we flatten X_train\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # Calculate the number of correct predicates\n",
    "        predicted = torch.max(y_pred.data, 1)[1] # the prediction that has the maximum probability\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad() # reset the gradients after each training step\n",
    "        loss.backward() # to trigger backprop\n",
    "        optimizer.step() # perform parameter update\n",
    "\n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2} batch: {b:4} [{100*b:6}/60000] Train loss: {loss.item():10.8f}')\n",
    "\n",
    "        # Update train loss & accuracy for the epoch\n",
    "        train_losses.append(loss)\n",
    "        train_correct.append(trn_corr)\n",
    "\n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test.view(500, -1))\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "\n",
    "            # Update test loss & accuracy for the epoch\n",
    "            loss = criterion(y_val, y_test)\n",
    "            test_losses.append(loss)\n",
    "            test_correct.append(tst_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.810%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy: {test_correct[-1].item()*100/10000:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ml-training/nb1.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpjirsa-ml-training-pwxg64qh67vw/workspaces/ml-training/nb1.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bpjirsa-ml-training-pwxg64qh67vw/workspaces/ml-training/nb1.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(train_losses, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining loss\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpjirsa-ml-training-pwxg64qh67vw/workspaces/ml-training/nb1.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(test_losses, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalidation loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpjirsa-ml-training-pwxg64qh67vw/workspaces/ml-training/nb1.ipynb#ch0000013vscode-remote?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mLoss at the end of each epoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2769\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2770\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2771\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:490\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[1;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mupdate_units(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1614\u001b[0m, in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1614\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(y)\n\u001b[1;32m   1615\u001b[0m \u001b[39mexcept\u001b[39;00m (np\u001b[39m.\u001b[39mVisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1616\u001b[0m     \u001b[39m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1306\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1304\u001b[0m x \u001b[39m=\u001b[39m _unpack_to_numpy(x)\n\u001b[1;32m   1305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1306\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[1;32m   1307\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1308\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    733\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
