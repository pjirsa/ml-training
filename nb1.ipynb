{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron for MNIST digits\n",
    "Trains a Multilayer Perceptron Neural network to detect hand-written digits.\n",
    "\n",
    "## First - import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f88f81358f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='./DATA', train=True, download=True, transform=Transform)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(root='./DATA', train=False, download=True, transform=Transform)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the first training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train[0]\n",
    "print('Shape:', image.shape, '\\nLabel:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size=784, output_size=10, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        self.d1 = nn.Linear(input_size,layers[0])\n",
    "        self.d2 = nn.Linear(layers[0],layers[1])\n",
    "        self.d3 = nn.Linear(layers[1],output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.d1(X))\n",
    "        X = F.relu(self.d2(X))\n",
    "        X = self.d3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilayerPerceptron()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('Initial Batch shape:', images.size())\n",
    "    break\n",
    "print('Batch shape after flattening',images.view(100,-1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with specified # of epochs (iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "\n",
    "        # Apply the model\n",
    "        y_pred = model(X_train.view(100, -1)) # Here we flatten X_train\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # Calculate the number of correct predicates\n",
    "        predicted = torch.max(y_pred.data, 1)[1] # the prediction that has the maximum probability\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad() # reset the gradients after each training step\n",
    "        loss.backward() # to trigger backprop\n",
    "        optimizer.step() # perform parameter update\n",
    "\n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2} batch: {b:4} [{100*b:6}/60000] Train loss: {loss.item():10.8f}')\n",
    "\n",
    "        # Update train loss & accuracy for the epoch\n",
    "        train_losses.append(loss)\n",
    "        train_correct.append(trn_corr)\n",
    "\n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test.view(500, -1))\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "\n",
    "            # Update test loss & accuracy for the epoch\n",
    "            loss = criterion(y_val, y_test)\n",
    "            test_losses.append(loss)\n",
    "            test_correct.append(tst_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test accuracy: {test_correct[-1].item()*100/10000:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optional* - use trained model on previously unseen data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
